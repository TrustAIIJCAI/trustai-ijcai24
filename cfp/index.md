---
layout: default
---

### Call for Papers

We invite submissions that address the following and related topic areas.

- Transparency, explainability, interpretability in ML models.
- Security and privacy concerns in ML models. 
- Misinformation detection. Data poisoning and adversarial examples.
- Audit techniques for data and ML models. 
- Fairness and exclusion studies (benchmarks and datasets).
- Evaluation for ensuring fair outcomes for all, especially underrepresented groups. 
- Robustness, safety, and collective value alignment, with a specific interest in measures that support developing countries and underrepresented communities.
- Social good, participatory AI, and applications of the above principles to different domains (e.g. healthcare, loans, legal).

### Instructions

If youâ€™re interested in presenting your work, please submit a 4-page paper (4 pages for content and 2 for references) following the [IJCAI Author Kit](https://www.ijcai.org/authors_kit) format. All submissions will be double-blind peer-reviewed by program committee members, with at least 2 submitted reviews per submission.

Submissions can include extra pages for technical appendices. There's no page limit for appendix content, but it's not mandatory for reviewers to go over the appendix. Only the main document is guaranteed to be read by reviewers.

Lastly, when published, IJCAI workshop papers are non-archival. We will host them on our website, but there will be no formal proceedings.

### Submission Link

Papers should be anonymized and submitted using [CMT](https://cmt3.research.microsoft.com/TrustAIWorkshop2024).

### Important Dates

Submission deadline: ~May 6, 2024~ **extended to May 10, 2024**

Paper notification: June 4, 2024

*Deadlines are at 11:59 PM AoE (Anywhere on Earth).*
